### সুপারভাইজড মেশিন লার্নিং -  জেনারালাইজেশন, ওভারফিটিং, আন্ডারফিটিং

---

সুপারভাইজড মেশিন লার্নিংয়ে আমাদের মূল লক্ষ্য হলো এমন একটি মডেল তৈরি করা যা ট্রেইনিং ডেটা থেকে শেখে, কিন্তু বাস্তব জগতে নতুন ডেটার উপরেও সঠিকভাবে কাজ করতে পারে। অর্থাৎ, মডেল যেন শুধু পুরনো ডেটা “মুখস্থ” না করে, বরং সমস্যার আসল প্যাটার্নটি বুঝে ফেলে। এই ক্ষমতাকেই বলা হয় জেনারালাইজেশন (Generalization)।

নেটওয়ার্কিংয়ের উদাহরণ দিয়ে বিষয়টি সহজে বোঝা যায়। ধরুন, আপনি বহু বছর ধরে বিভিন্ন ধরনের নেটওয়ার্ক ইনসিডেন্ট সামলেছেন। এখন কোনো নতুন সমস্যা দেখা দিলে, আপনি ঠিক একই ঘটনা আগে না দেখলেও লক্ষণগুলো দেখে অনুমান করতে পারেন কী হতে পারে। কারণ আপনি নির্দিষ্ট ঘটনাগুলো নয়, বরং তাদের সাধারণ আচরণ বা প্যাটার্ন শিখেছেন। একটি ভালো মেশিন লার্নিং মডেলও ঠিক এভাবেই কাজ করে।

<img src="04-ai-ml-1.png" width="900">

**ট্রেইনিং ডেটায় ভালো মানেই বাস্তবে ভালো নয়**

সাধারণত আমরা প্রথমে দেখি মডেল ট্রেইনিং ডেটার উপর কতটা সঠিক ফল দিচ্ছে। যদি ট্রেইনিং ডেটা এবং ভবিষ্যতের ডেটার প্রকৃতি একই রকম হয়, তাহলে আশা করা যায় মডেল নতুন ডেটার উপরেও ভালো করবে। কিন্তু বাস্তবে সবসময় বিষয়টি এত সহজ নয়।

যদি মডেলকে খুব বেশি জটিল হতে দেওয়া হয়, তাহলে এটি ট্রেইনিং ডেটার প্রতিটি ছোটখাটো বৈশিষ্ট্য, এমনকি কাকতালীয় বিষয়ও শিখে ফেলে। তখন ট্রেইনিং ডেটায় এটি প্রায় নিখুঁত ফলাফল দেখায়। কিন্তু নতুন ডেটা এলে একই ধরনের পরিস্থিতি না থাকায় মডেল ভুল Prediction করতে শুরু করে।

**একটি বাস্তবসম্মত উদাহরণ**

ধরুন আপনি NetFlow ডেটা ব্যবহার করে একটি DDoS শনাক্তকরণ সিস্টেম তৈরি করছেন। আপনার কাছে কিছু পুরনো ট্রাফিক রেকর্ড আছে—যেখানে জানা আছে কোনগুলো আক্রমণ ছিল এবং কোনগুলো স্বাভাবিক ট্রাফিক। একজন ইঞ্জিনিয়ার দীর্ঘ সময় ধরে ডেটা পর্যবেক্ষণ করে একটি জটিল নিয়ম তৈরি করল। উদাহরণস্বরূপ, সে বলল, “যদি PPS একটি নির্দিষ্ট মানের বেশি হয়, SYN প্যাকেটের অনুপাত বেশি হয়, TTL ভ্যারিয়েশন কম হয় এবং নির্দিষ্ট কিছু পোর্ট ব্যবহার না হয়—তাহলে এটি DDoS”। এই নিয়মটি ট্রেইনিং ডেটার উপর ১০০% সঠিক হতে পারে। কিন্তু বাস্তবে আক্রমণের ধরন পরিবর্তিত হতে পারে, বৈধ ট্রাফিকও কখনো কখনো একই রকম আচরণ করতে পারে, অথবা নতুন ধরনের অ্যাপ্লিকেশন ভিন্ন প্যাটার্ন তৈরি করতে পারে। ফলে এই নিয়মটি নতুন পরিস্থিতিতে ব্যর্থ হতে পারে। অর্থাৎ, ট্রেইনিং ডেটায় নিখুঁত ফলাফল পাওয়া মানেই বাস্তব জগতে কার্যকর হবে—এমন কোনো নিশ্চয়তা নেই।

**জেনারালাইজেশন এর আসল লক্ষ্য**

একটি ভালো মডেল হলো সেই মডেল, যা নতুন ডেটার উপরেও সঠিক সিদ্ধান্ত নিতে পারে। এই কারণেই মেশিন লার্নিংয়ে সাধারণত ট্রেইনিং ডেটা থেকে আলাদা একটি “টেস্ট সেট” ব্যবহার করা হয়—যাতে বোঝা যায় মডেল আগে না দেখা ডেটার উপর কেমন কাজ করছে। যদি মডেল টেস্ট ডেটাতেও ভালো ফল দেয়, তাহলে ধরে নেওয়া যায় এটি সমস্যার মূল প্যাটার্ন বুঝেছে।

**ওভারফিটিং — মডেল যখন “অতিরিক্ত শেখে”**

যখন একটি মডেল ট্রেইনিং ডেটার প্রতি অতিরিক্ত সংবেদনশীল হয়ে পড়ে এবং নতুন ডেটার উপর কাজ করতে পারে না, তখন তাকে বলা হয় ওভারফিটিং (Overfitting)। নেটওয়ার্কিংয়ের ভাষায়, এটি এমন একজন ইঞ্জিনিয়ারের মতো যিনি কয়েকটি নির্দিষ্ট ইনসিডেন্ট দেখে এমন একটি জটিল নিয়ম তৈরি করেছে যা শুধুমাত্র সেই ঘটনাগুলোর জন্যই কার্যকর। নতুন ধরনের সমস্যা এলে এই নিয়ম আর কাজ করে না।

ওভারফিটিং সাধারণত ঘটে যখন — মডেল অত্যন্ত জটিল হয়, ডেটা কম এবং ডেটার বৈচিত্র্যও কম, অপ্রয়োজনীয় ফিচার বেশি ব্যবহার করা হয়।

**আন্ডারফিটিং — যখন মডেল “যথেষ্ট শেখে না”**

এর বিপরীত সমস্যা হলো আন্ডারফিটিং (Underfitting)। এখানে মডেল এতটাই সরল যে ডেটার গুরুত্বপূর্ণ প্যাটার্নই ধরতে পারে না। ধরুন কেউ একটি নিয়ম বানাল— “যে কোনো ট্রাফিক স্পাইক মানেই আক্রমণ”।এই নিয়মটি বাস্তবের জটিলতা ধরতে পারে না। অনেক স্বাভাবিক ট্রাফিকও ভুলভাবে আক্রমণ হিসেবে চিহ্নিত হবে, এবং মডেল ট্রেইনিং ডেটাতেও ভালো ফল দিতে পারবে না।

**সঠিক ভারসাম্য খুঁজে পাওয়া**

মডেলের জটিলতা বাড়ালে ট্রেইনিং ডেটায় পারফরম্যান্স সাধারণত বাড়ে। কিন্তু একটি পর্যায়ের পর অতিরিক্ত জটিলতা নতুন ডেটায় পারফরম্যান্স কমিয়ে দেয়। অন্যদিকে খুব সরল মডেল শুরু থেকেই খারাপ ফল দেয়। এই দুই অবস্থার মাঝখানে একটি আদর্শ বিন্দু থাকে —যেখানে মডেল সবচেয়ে ভালোভাবে নতুন ডেটায় কাজ করে। মেশিন লার্নিংয়ে আমরা সাধারণত এই ভারসাম্যপূর্ণ মডেলটিই খুঁজে বের করার চেষ্টা করি।

**ডেটার পরিমাণ ও বৈচিত্র্যের ভূমিকা**

মডেল কতটা জটিল হতে পারে তা অনেকটাই নির্ভর করে ট্রেইনিং ডেটার পরিমাণ এবং বৈচিত্র্যের উপর। যদি ডেটায় বিভিন্ন সময়, বিভিন্ন ট্রাফিক ধরন, বিভিন্ন নেটওয়ার্ক অবস্থা এবং বিভিন্ন ব্যবহারকারীর আচরণ অন্তর্ভুক্ত থাকে, তাহলে মডেল বাস্তবসম্মতভাবে শেখার সুযোগ পায়। কিন্তু একই ধরনের ডেটা বারবার সংগ্রহ করলে তেমন উপকার হয় না। কারণ এতে নতুন তথ্য যোগ হয় না।

উদাহরণস্বরূপ, যদি আপনি হাজার হাজার DDoS ইনসিডেন্টের ডেটা সংগ্রহ করেন বিভিন্ন পরিস্থিতি থেকে, তাহলে একটি জটিল মডেলও নির্ভরযোগ্য হতে পারে। কিন্তু মাত্র কয়েকটি ইনসিডেন্ট থেকে জটিল সিদ্ধান্ত তৈরি করলে সেটি ঝুঁকিপূর্ণ হবে।

**একজন নেটওয়ার্ক ইঞ্জিনিয়ারের জন্য মূল শিক্ষা**

মেশিন লার্নিংয়ের সফলতা শুধু অ্যালগরিদমের উপর নির্ভর করে না; বরং ডেটার মান, বৈচিত্র্য এবং সমস্যার সঠিক বোঝাপড়ার উপর নির্ভর করে। এটি অনেকটা নেটওয়ার্ক ডিজাইন বা ট্রাবলশুটিংয়ের মতো—যেখানে অভিজ্ঞতা, পর্যবেক্ষণ এবং বাস্তব পরিস্থিতির জ্ঞান সবচেয়ে গুরুত্বপূর্ণ।

একটি ভালো মেশিন লার্নিং মডেল ঠিক একজন অভিজ্ঞ নেটওয়ার্ক ইঞ্জিনিয়ারের মতো—যা নির্দিষ্ট ঘটনাকে নয়, বরং নেটওয়ার্কের আচরণের মৌলিক নিয়মগুলো বুঝে সিদ্ধান্ত নিতে পারে, এবং নতুন পরিস্থিতিতেও কার্যকর থাকে।

